<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Viewset Diffusion trains image-conditioned 3D generative models from 2D data.">
  <meta name="keywords" content="Diffusion, 3D Generation, 3D Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Viewset Diffusion: 3D Generative Models from 2D Data</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./viewset-diffusion-static/css/bulma.min.css">
  <link rel="stylesheet" href="./viewset-diffusion-static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./viewset-diffusion-static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./viewset-diffusion-static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./viewset-diffusion-static/css/index.css">
  <link rel="icon" href="./viewset-diffusion-static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./viewset-diffusion-static/js/fontawesome.all.min.js"></script>
  <script src="./viewset-diffusion-static/js/bulma-carousel.min.js"></script>
  <script src="./viewset-diffusion-static/js/bulma-slider.min.js"></script>
  <script src="./viewset-diffusion-static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://szymanowiczs.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://szymanowiczs.github.io/splatter-image">
            Splatter Image
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2208.00949">
            VolTeMorph
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2210.11594">
            360 Avatars
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://szymanowiczs.github.io">Stanislaw Szymanowicz</a>,</span>
            <span class="author-block">
              <a href="https://chrirupp.github.io">Christian Rupprecht</a>,</span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Visual Geometry Group - University of Oxford</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. 
              <span class="link-block">
                <a href="https://szymanowiczs.github.io/viewset-diffusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2306.07881"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/szymanowiczs/viewset-diffusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/13Gk6nJnBjDdl3N2_yjmSomRg6gLrpIZv?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content has-text-centered">
        <img src="./viewset-diffusion-static/images/teaser_figure_arxiv_with_circle.pdf"
                class="interpolation-image"
                alt="Method figure."/>
      </div>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Viewset Diffusion</span> trains image-conditioned 3D generative models from 2D data.
        A single model is capable of both ambiguity-aware 3D reconstruction and unconditional 3D generation.
      </h2>
      <div class="content has-text-centered">
        <video id="summary-video"
               controls
               muted
               loop
               autoplay
               preload
               playsinline
               width="75%">
          <source src="viewset-diffusion-static/videos/summary_website.m4v"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
   
   
          <p>
            We present Viewset Diffusion: a framework for training image-conditioned 3D generative models from 2D data. 
          </p>
          <p>
            Image-conditioned 3D generative models tackle the inherent ambiguity in single-view 3D 
            reconstruction: given one image of an object, there is often more than one possible 3D 
            volume that matches the input image.
            This problem is often treated as a deterministic task, 
            where a single instance of a 3D volume is regressed or 
            optimised given an input image. 
            However, a single image never captures all sides of an object.
            Deterministic models are inherently limited to producing one possible reconstruction 
            and therefore make mistakes in ambiguous settings. 
            We treat 3D reconstruction as a conditional generation task to capture ambiguities.
          </p>
          <p>
            Modelling the distributions of 3D shapes is challenging because often 3D ground truth data is not available. 
            We propose to solve the issue of data availability by training a conditional 
            diffusion model which jointly denoises a multi-view image set.
            The input image set can consist of any number of 'clean' (conditioning) and 'noisy' (target) images.
            We constrain output of Viewset Diffusion models to a single 3D volume per image set, guaranteeing consistent geometry.
            Training is done through reconstruction losses on renderings, allowing training with only three images per object. 
            Our design of architecture and training scheme allows our model to perform 3D generation and generative, ambiguity-aware single-view reconstruction in a feed-forward manner.
          
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!--/<div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <h2 class="title is-3" style="margin-bottom:2cm;">Results (scroll horizontally for more classes) </h2>
      </div>
      <div class="columns is-centered">
        <h3 class="title is-4">Single-view 3D Reconstruction (non-cherry-picked)</h3>
      </div>
      <div id="results-carousel" class="carousel results-carousel" >
        
        <div class="item item-cars1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_cars_1_view_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-cars2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_cars_1_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-hydrants1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_hydrants_1_view_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hydrants2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_hydrants_1_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-mine1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_mine_1_view_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mine2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/sbs_mine_1_view_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-teddy">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/teddy_1_view_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-plant">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/plant_1_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-vase">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="viewset-diffusion-static/results/1_view/vase_1_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <h3 class="title is-4">Unconditional 3D Generation (non-cherry-picked)</h3>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-cars1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/cars_0_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-cars2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/cars_0_view_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-cars3">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/cars_0_view_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hydrants1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/hydrarnts_0_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hydrants2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/hydrarnts_0_view_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hydrants4">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/hydrants_0_view_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mine1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/mine_0_view_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mine2">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/mine_0_view_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mine3">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/mine_0_view_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-teddy_uc1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/teddy_0_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-plant_uc1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/plant_0_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-vase_uc1">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="50%">
            <source src="viewset-diffusion-static/results/0_view/vase_0_view_3.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    
  
    <!-- More. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Ambiguity. -->
        <h3 class="title is-4">Ambiguity</h3>
        <div class="content has-text-justified">
          <p>
            Under presence of ambiguity, deterministic methods blur possible shapes (orange car’s back, 
            Minecraft characters’ poses) and colours (black car’s back, occluded sides of Minecraft characters). 
            Our method samples plausible 3D reconstructions.
          </p>
        </div>
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <img src="./viewset-diffusion-static/images/ambiguity_figure_v2.pdf"
                class="interpolation-image"
                alt="Ambiguity figure."/>
          </div>
        </div>
        <!--/ Ambiguity. -->



        <!-- Method. -->

        <h3 class="title is-4">Method</h3>
        <div class="content has-text-justified">
          <p>
            Viewset Diffusion takes in any number of clean conditioning images and
            target images with Gaussian noise and jointly denoises the input image set. 
            The denoising function is defined as reconstructing 
            and rendering a 3D volume. When there is at least one clean conditioning view, 
            Viewset Diffusion samples plausible 3D reconstructions. When all input views are noisy, 
            Viewset Diffusion generates 3D volumes.
          </p>
        </div>
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <img src="./viewset-diffusion-static/images/method_figure_arxiv.pdf"
                class="interpolation-image"
                alt="Method figure."/>
          </div>
        </div>

        <!--/ Method. -->
        <h3 class="title is-4">Related works</h3>
        <div class="content has-text-justified">
          <p>
            Also check out a great, related paper <a href="https://diffusion-with-forward-models.github.io">Diffusion with Forward Models</a>.
          </p>
        </div>


      </div>
    </div> 

    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{szymanowicz2023viewset_diffusion,
  author    = {Szymanowicz, Stanislaw and Rupprecht, Christian and Vedaldi, Andrea},
  title     = {Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data},
  journal   = {International Conference on Computer Vision},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2306.07881.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/szymanowiczs/viewset-diffusion" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Template was borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>